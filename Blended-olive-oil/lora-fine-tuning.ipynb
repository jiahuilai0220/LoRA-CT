{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import loralib as lora\n",
    "from model import CNN\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import optuna\n",
    "import json\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error, mean_absolute_error, max_error\n",
    "import matplotlib.pyplot as plt\n",
    "# Determine the equipment\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters tuning of LoRA-CT method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-17 16:48:00,832] A new study created in memory with name: no-name-1b24f87a-6765-4872-b460-7bd3a5f72919\n",
      "[I 2025-02-17 16:48:03,298] Trial 0 finished with value: 0.182222316595678 and parameters: {'Learning rate': 1e-05, 'Regularization coefficient': 0.001, 'Lora rank': 8}. Best is trial 0 with value: 0.182222316595678.\n",
      "[I 2025-02-17 16:48:03,986] Trial 1 finished with value: 0.8542046695376616 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.01, 'Lora rank': 6}. Best is trial 1 with value: 0.8542046695376616.\n",
      "[I 2025-02-17 16:48:04,649] Trial 2 finished with value: -0.24013737438407445 and parameters: {'Learning rate': 1e-05, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 1 with value: 0.8542046695376616.\n",
      "[I 2025-02-17 16:48:05,296] Trial 3 finished with value: -0.540968811565901 and parameters: {'Learning rate': 1e-05, 'Regularization coefficient': 0.1, 'Lora rank': 2}. Best is trial 1 with value: 0.8542046695376616.\n",
      "[I 2025-02-17 16:48:06,019] Trial 4 finished with value: 0.006445898091810176 and parameters: {'Learning rate': 1e-05, 'Regularization coefficient': 0.001, 'Lora rank': 6}. Best is trial 1 with value: 0.8542046695376616.\n",
      "[I 2025-02-17 16:48:06,785] Trial 5 finished with value: 0.8542046695376616 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.01, 'Lora rank': 6}. Best is trial 1 with value: 0.8542046695376616.\n",
      "[I 2025-02-17 16:48:07,449] Trial 6 finished with value: -0.5409358665808179 and parameters: {'Learning rate': 1e-05, 'Regularization coefficient': 0.001, 'Lora rank': 2}. Best is trial 1 with value: 0.8542046695376616.\n",
      "[I 2025-02-17 16:48:08,079] Trial 7 finished with value: 0.8558254651572436 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.001, 'Lora rank': 2}. Best is trial 7 with value: 0.8558254651572436.\n",
      "[I 2025-02-17 16:48:08,730] Trial 8 finished with value: 0.5983754980500535 and parameters: {'Learning rate': 0.0001, 'Regularization coefficient': 0.001, 'Lora rank': 8}. Best is trial 7 with value: 0.8558254651572436.\n",
      "[I 2025-02-17 16:48:09,377] Trial 9 finished with value: -0.24013737438407445 and parameters: {'Learning rate': 1e-05, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 7 with value: 0.8558254651572436.\n",
      "[I 2025-02-17 16:48:10,055] Trial 10 finished with value: 0.7942308685198727 and parameters: {'Learning rate': 0.01, 'Regularization coefficient': 0.1, 'Lora rank': 2}. Best is trial 7 with value: 0.8558254651572436.\n",
      "[I 2025-02-17 16:48:10,698] Trial 11 finished with value: 0.8542046695376616 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.01, 'Lora rank': 6}. Best is trial 7 with value: 0.8558254651572436.\n",
      "[I 2025-02-17 16:48:11,377] Trial 12 finished with value: 0.8542046695376616 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.01, 'Lora rank': 6}. Best is trial 7 with value: 0.8558254651572436.\n",
      "[I 2025-02-17 16:48:12,038] Trial 13 finished with value: 0.8558152120002398 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.01, 'Lora rank': 2}. Best is trial 7 with value: 0.8558254651572436.\n",
      "[I 2025-02-17 16:48:12,660] Trial 14 finished with value: 0.8558152120002398 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.01, 'Lora rank': 2}. Best is trial 7 with value: 0.8558254651572436.\n",
      "[I 2025-02-17 16:48:13,293] Trial 15 finished with value: 0.7942308685198727 and parameters: {'Learning rate': 0.01, 'Regularization coefficient': 0.1, 'Lora rank': 2}. Best is trial 7 with value: 0.8558254651572436.\n",
      "[I 2025-02-17 16:48:13,941] Trial 16 finished with value: 0.5441386098003851 and parameters: {'Learning rate': 0.0001, 'Regularization coefficient': 0.01, 'Lora rank': 2}. Best is trial 7 with value: 0.8558254651572436.\n",
      "[I 2025-02-17 16:48:14,619] Trial 17 finished with value: 0.8558152120002398 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.01, 'Lora rank': 2}. Best is trial 7 with value: 0.8558254651572436.\n",
      "[I 2025-02-17 16:48:15,267] Trial 18 finished with value: 0.8558254651572436 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.001, 'Lora rank': 2}. Best is trial 7 with value: 0.8558254651572436.\n",
      "[I 2025-02-17 16:48:15,912] Trial 19 finished with value: 0.8592948346033483 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:16,570] Trial 20 finished with value: 0.5676173442728756 and parameters: {'Learning rate': 0.0001, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:17,241] Trial 21 finished with value: 0.8592948346033483 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:17,885] Trial 22 finished with value: 0.8592948346033483 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:18,514] Trial 23 finished with value: 0.8592948346033483 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:19,182] Trial 24 finished with value: 0.8141561236549429 and parameters: {'Learning rate': 0.01, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:19,840] Trial 25 finished with value: 0.8592948346033483 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:20,472] Trial 26 finished with value: 0.8592948346033483 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:21,103] Trial 27 finished with value: 0.8591778660097502 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.1, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:21,762] Trial 28 finished with value: 0.8592948346033483 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:22,458] Trial 29 finished with value: 0.7556995735701083 and parameters: {'Learning rate': 0.01, 'Regularization coefficient': 0.001, 'Lora rank': 8}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:23,088] Trial 30 finished with value: 0.5676173442728756 and parameters: {'Learning rate': 0.0001, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:23,732] Trial 31 finished with value: 0.8592948346033483 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:24,408] Trial 32 finished with value: 0.8592948346033483 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:25,068] Trial 33 finished with value: 0.8592948346033483 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:25,718] Trial 34 finished with value: 0.8592948346033483 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:26,368] Trial 35 finished with value: 0.8536466917624106 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.001, 'Lora rank': 8}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:27,042] Trial 36 finished with value: 0.8591778660097502 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.1, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:27,681] Trial 37 finished with value: -0.24013737438407445 and parameters: {'Learning rate': 1e-05, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:28,324] Trial 38 finished with value: 0.8592948346033483 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:29,003] Trial 39 finished with value: 0.8592948346033483 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:29,699] Trial 40 finished with value: 0.182222316595678 and parameters: {'Learning rate': 1e-05, 'Regularization coefficient': 0.001, 'Lora rank': 8}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:30,358] Trial 41 finished with value: 0.8592948346033483 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:31,042] Trial 42 finished with value: 0.8592948346033483 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:31,706] Trial 43 finished with value: 0.8592948346033483 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:32,372] Trial 44 finished with value: 0.8542109408711285 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.001, 'Lora rank': 6}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:33,038] Trial 45 finished with value: 0.8592948346033483 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:33,694] Trial 46 finished with value: 0.5675978811450872 and parameters: {'Learning rate': 0.0001, 'Regularization coefficient': 0.1, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:34,351] Trial 47 finished with value: 0.8592948346033483 and parameters: {'Learning rate': 0.001, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:35,042] Trial 48 finished with value: 0.7181207715523067 and parameters: {'Learning rate': 0.01, 'Regularization coefficient': 0.001, 'Lora rank': 6}. Best is trial 19 with value: 0.8592948346033483.\n",
      "[I 2025-02-17 16:48:35,694] Trial 49 finished with value: -0.24013737438407445 and parameters: {'Learning rate': 1e-05, 'Regularization coefficient': 0.001, 'Lora rank': 4}. Best is trial 19 with value: 0.8592948346033483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal hyperparameter results: {'Learning rate': 0.001, 'Regularization coefficient': 0.001, 'Lora rank': 4}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Modifying the primary model architecture\n",
    "def get_peft_model(base_model, lora_rank, lora_alpha):\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    class PeftModel(nn.Module):\n",
    "        def __init__(self, base_model, lora_rank, lora_alpha):\n",
    "            super(PeftModel, self).__init__()\n",
    "            for name, module in base_model.named_children():\n",
    "                if name != 'Linear':\n",
    "                    self.add_module(name, module)\n",
    "                else:\n",
    "                    self.add_module(name, lora.Linear(base_model.Linear.in_features, base_model.Linear.out_features, r=lora_rank, lora_alpha=lora_alpha, merge_weights=True))\n",
    "            \n",
    "        def forward(self, x):\n",
    "            for module in self.children():\n",
    "                x = module(x)\n",
    "            return x.squeeze(dim=1)\n",
    "    \n",
    "    return PeftModel(base_model, lora_rank, lora_alpha)\n",
    "\n",
    "def opt_model(trial):\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    # Hyperparameter definitions\n",
    "    learning_rate = trial.suggest_categorical(\"Learning rate\", [1e-5, 1e-4, 1e-3, 1e-2])\n",
    "    weight_decay = trial.suggest_categorical(\"Regularization coefficient\", [1e-3, 1e-2, 1e-1])\n",
    "    lora_rank = trial.suggest_categorical(\"Lora rank\", [2, 4, 6, 8])\n",
    "    lora_alpha = lora_rank \n",
    "\n",
    "    Path2 = 'oil-data\\\\iRaman_processed_spectra.csv'\n",
    "    X = pd.read_csv(Path2, header=None, index_col=None)\n",
    "    X = np.array(X)\n",
    "    \n",
    "    y_path = 'oil-data\\\\Olive oil labels.csv'\n",
    "    y = pd.read_csv(y_path, header=None)\n",
    "    y = np.array(y)\n",
    "    y = y.reshape(-1)\n",
    "    \n",
    "    X_trans, X_val, y_trans, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=42)\n",
    "\n",
    "    X_train, X_left, y_train, y_left = train_test_split(X_trans, y_trans, test_size=0.85, random_state=12)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Convert data to tensor and make sure it's on the right device\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "    X_val = torch.tensor(X_val, dtype=torch.float32, device=device)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.float32, device=device)\n",
    "    y_val = torch.tensor(y_val, dtype=torch.float32, device=device)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.float32, device=device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=len(y_train), shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=len(y_val), shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=len(y_test), shuffle=False)\n",
    "\n",
    "    # Load pre-trained model\n",
    "    model_state_dict = torch.load('oil-best_model_cnn_x1.pt', map_location=device, weights_only=True)\n",
    "    base_model = CNN()\n",
    "    peft_model = get_peft_model(base_model, lora_rank, lora_alpha).to(device)\n",
    "    peft_model.load_state_dict(model_state_dict, strict=False)\n",
    "\n",
    "    # Perform weight decay\n",
    "    original_weight = peft_model.Linear.weight.data\n",
    "    decayed_weight = original_weight * 0.5\n",
    "    peft_model.Linear.weight.data = decayed_weight\n",
    "    #Confirm the layers to be trained\n",
    "    lora.mark_only_lora_as_trainable(peft_model)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(peft_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    loss_fn = nn.SmoothL1Loss().to(device)\n",
    "    epochs = 100\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        peft_model.train()\n",
    "        train_loss = 0\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x = batch_x.unsqueeze(dim=1).to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            outputs = peft_model(batch_x)\n",
    "            loss = loss_fn(outputs, batch_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "    peft_model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in val_loader:\n",
    "            batch_x = batch_x.unsqueeze(dim=1).to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            output = peft_model(batch_x)\n",
    "            predictions.extend(output.cpu().tolist())\n",
    "            actuals.extend(batch_y.cpu().tolist())\n",
    "\n",
    "    if len(predictions) >= 2:\n",
    "        r2 = r2_score(actuals, predictions)\n",
    "    return r2\n",
    "\n",
    "# hyperparameters tuning\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(opt_model, n_trials=50)\n",
    "print('Optimal hyperparameter results:', study.best_params)\n",
    "\n",
    "# Save the best hyperparameters\n",
    "best_params = study.best_params\n",
    "with open('lora_peft_best_hyperparameters_15%.json', 'w') as f:\n",
    "    json.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the optimal combination of hyperparameters of the LoRA-CT method for fine-tuned training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.021785734221339226, Val Loss: 0.0275582168251276\n",
      "Epoch 2, Train Loss: 0.021516209468245506, Val Loss: 0.01655777357518673\n",
      "Epoch 3, Train Loss: 0.014835687354207039, Val Loss: 0.006087359506636858\n",
      "Epoch 4, Train Loss: 0.00770574202761054, Val Loss: 0.008704169653356075\n",
      "Epoch 5, Train Loss: 0.010417154058814049, Val Loss: 0.00904929731041193\n",
      "Epoch 6, Train Loss: 0.0109076714143157, Val Loss: 0.005472459830343723\n",
      "Epoch 7, Train Loss: 0.007456626743078232, Val Loss: 0.005523446947336197\n",
      "Epoch 8, Train Loss: 0.006679190788418055, Val Loss: 0.007751103024929762\n",
      "Epoch 9, Train Loss: 0.007957404479384422, Val Loss: 0.009211494587361813\n",
      "Epoch 10, Train Loss: 0.00890081562101841, Val Loss: 0.009068391285836697\n",
      "Epoch 11, Train Loss: 0.008688198402523994, Val Loss: 0.007719746325165033\n",
      "Epoch 12, Train Loss: 0.007589094340801239, Val Loss: 0.006082099862396717\n",
      "Epoch 13, Train Loss: 0.006418109871447086, Val Loss: 0.005264684092253447\n",
      "Epoch 14, Train Loss: 0.006161135621368885, Val Loss: 0.005584034603089094\n",
      "Epoch 15, Train Loss: 0.006937955506145954, Val Loss: 0.005888575222343206\n",
      "Epoch 16, Train Loss: 0.007354676723480225, Val Loss: 0.005496948957443237\n",
      "Epoch 17, Train Loss: 0.006658766884356737, Val Loss: 0.005227473098784685\n",
      "Epoch 18, Train Loss: 0.005827500484883785, Val Loss: 0.005658486858010292\n",
      "Epoch 19, Train Loss: 0.005680606700479984, Val Loss: 0.006403499282896519\n",
      "Epoch 20, Train Loss: 0.005999850109219551, Val Loss: 0.006839792709797621\n",
      "Epoch 21, Train Loss: 0.006212514825165272, Val Loss: 0.006690403912216425\n",
      "Epoch 22, Train Loss: 0.0060300398617982864, Val Loss: 0.006081996485590935\n",
      "Epoch 23, Train Loss: 0.005547645501792431, Val Loss: 0.005400130990892649\n",
      "Epoch 24, Train Loss: 0.0051040551625192165, Val Loss: 0.005028316751122475\n",
      "Epoch 25, Train Loss: 0.005000615958124399, Val Loss: 0.0049982862547039986\n",
      "Epoch 26, Train Loss: 0.0051450286991894245, Val Loss: 0.004988120868802071\n",
      "Epoch 27, Train Loss: 0.00510283000767231, Val Loss: 0.004857489373534918\n",
      "Epoch 28, Train Loss: 0.0047248112969100475, Val Loss: 0.0048322128131985664\n",
      "Epoch 29, Train Loss: 0.004336693324148655, Val Loss: 0.005050877574831247\n",
      "Epoch 30, Train Loss: 0.004201232455670834, Val Loss: 0.005324218887835741\n",
      "Epoch 31, Train Loss: 0.004211768973618746, Val Loss: 0.005366089288145304\n",
      "Epoch 32, Train Loss: 0.004111771937459707, Val Loss: 0.005081263370811939\n",
      "Epoch 33, Train Loss: 0.0037999157793819904, Val Loss: 0.004645346198230982\n",
      "Epoch 34, Train Loss: 0.0034206178970634937, Val Loss: 0.004334136378020048\n",
      "Epoch 35, Train Loss: 0.0031890147365629673, Val Loss: 0.004216584376990795\n",
      "Epoch 36, Train Loss: 0.0030859822873026133, Val Loss: 0.0041184211149811745\n",
      "Epoch 37, Train Loss: 0.002865258138626814, Val Loss: 0.003997620195150375\n",
      "Epoch 38, Train Loss: 0.002495676977559924, Val Loss: 0.004017803352326155\n",
      "Epoch 39, Train Loss: 0.002233309904113412, Val Loss: 0.004130392801016569\n",
      "Epoch 40, Train Loss: 0.002130292123183608, Val Loss: 0.0040301247499883175\n",
      "Epoch 41, Train Loss: 0.0019287581089884043, Val Loss: 0.003686206415295601\n",
      "Epoch 42, Train Loss: 0.0015852234791964293, Val Loss: 0.0034447715152055025\n",
      "Epoch 43, Train Loss: 0.0013859540922567248, Val Loss: 0.0033715800382196903\n",
      "Epoch 44, Train Loss: 0.001302064978517592, Val Loss: 0.0032421534415334463\n",
      "Epoch 45, Train Loss: 0.0010653708595782518, Val Loss: 0.003203421598300338\n",
      "Epoch 46, Train Loss: 0.0009047389030456543, Val Loss: 0.003238669829443097\n",
      "Epoch 47, Train Loss: 0.0008977398392744362, Val Loss: 0.0030457579996436834\n",
      "Epoch 48, Train Loss: 0.0007380166207440197, Val Loss: 0.002914425916969776\n",
      "Epoch 49, Train Loss: 0.0006670323200523853, Val Loss: 0.0029056512285023928\n",
      "Epoch 50, Train Loss: 0.0006928470684215426, Val Loss: 0.0027795990463346243\n",
      "Epoch 51, Train Loss: 0.0005827354034408927, Val Loss: 0.002774398308247328\n",
      "Epoch 52, Train Loss: 0.0006319375243037939, Val Loss: 0.0026931993197649717\n",
      "Epoch 53, Train Loss: 0.0005998102715238929, Val Loss: 0.002651431132107973\n",
      "Epoch 54, Train Loss: 0.0005737208994105458, Val Loss: 0.0026592733338475227\n",
      "Epoch 55, Train Loss: 0.0006071150419302285, Val Loss: 0.0025215144269168377\n",
      "Epoch 56, Train Loss: 0.0005347969708964229, Val Loss: 0.0024865535087883472\n",
      "Epoch 57, Train Loss: 0.000566740520298481, Val Loss: 0.0024155688006430864\n",
      "Epoch 58, Train Loss: 0.0004884215304628015, Val Loss: 0.0024336904752999544\n",
      "Epoch 59, Train Loss: 0.0004836522857658565, Val Loss: 0.0023496681824326515\n",
      "Epoch 60, Train Loss: 0.00042140186997130513, Val Loss: 0.002264531794935465\n",
      "Epoch 61, Train Loss: 0.0003802517894655466, Val Loss: 0.0022207351867109537\n",
      "Epoch 62, Train Loss: 0.0003404952003620565, Val Loss: 0.0021852347999811172\n",
      "Epoch 63, Train Loss: 0.00027985332417301834, Val Loss: 0.0021684831008315086\n",
      "Epoch 64, Train Loss: 0.00025955989258363843, Val Loss: 0.0020952278282493353\n",
      "Epoch 65, Train Loss: 0.0001997361541725695, Val Loss: 0.0020769615657627583\n",
      "Epoch 66, Train Loss: 0.00019089713168796152, Val Loss: 0.002037139842286706\n",
      "Epoch 67, Train Loss: 0.00014636447303928435, Val Loss: 0.002030033618211746\n",
      "Epoch 68, Train Loss: 0.00014013533655088395, Val Loss: 0.0020000413060188293\n",
      "Epoch 69, Train Loss: 0.00011689984239637852, Val Loss: 0.0019825815688818693\n",
      "Epoch 70, Train Loss: 0.00010815557470778003, Val Loss: 0.0019699824042618275\n",
      "Epoch 71, Train Loss: 0.00010325890616513789, Val Loss: 0.0019498810870572925\n",
      "Epoch 72, Train Loss: 9.127902012551203e-05, Val Loss: 0.001944639254361391\n",
      "Epoch 73, Train Loss: 9.615672752261162e-05, Val Loss: 0.0019244326977059245\n",
      "Epoch 74, Train Loss: 8.382660598726943e-05, Val Loss: 0.0019213709747418761\n",
      "Epoch 75, Train Loss: 8.939844701671973e-05, Val Loss: 0.0019030998228117824\n",
      "Epoch 76, Train Loss: 7.950374856591225e-05, Val Loss: 0.0018951707752421498\n",
      "Epoch 77, Train Loss: 8.04322335170582e-05, Val Loss: 0.0018821575213223696\n",
      "Epoch 78, Train Loss: 7.385572098428383e-05, Val Loss: 0.0018719654763117433\n",
      "Epoch 79, Train Loss: 6.928808579687029e-05, Val Loss: 0.0018623542273417115\n",
      "Epoch 80, Train Loss: 6.524995842482895e-05, Val Loss: 0.0018504159525036812\n",
      "Epoch 81, Train Loss: 5.704041541321203e-05, Val Loss: 0.001844811369664967\n",
      "Epoch 82, Train Loss: 5.430931196315214e-05, Val Loss: 0.0018315790221095085\n",
      "Epoch 83, Train Loss: 4.5033939386485144e-05, Val Loss: 0.0018252476584166288\n",
      "Epoch 84, Train Loss: 4.2933977965731174e-05, Val Loss: 0.0018181635532528162\n",
      "Epoch 85, Train Loss: 3.447243943810463e-05, Val Loss: 0.0018192596035078168\n",
      "Epoch 86, Train Loss: 3.290758832008578e-05, Val Loss: 0.0018095240229740739\n",
      "Epoch 87, Train Loss: 2.6234101824229583e-05, Val Loss: 0.001803716877475381\n",
      "Epoch 88, Train Loss: 2.536539250286296e-05, Val Loss: 0.0018031928921118379\n",
      "Epoch 89, Train Loss: 2.056740049738437e-05, Val Loss: 0.0018099703593179584\n",
      "Epoch 90, Train Loss: 2.0357489120215178e-05, Val Loss: 0.0018043018644675612\n",
      "Epoch 91, Train Loss: 1.703894122329075e-05, Val Loss: 0.0017993201036006212\n",
      "Epoch 92, Train Loss: 1.7282131011597812e-05, Val Loss: 0.0018028179183602333\n",
      "Epoch 93, Train Loss: 1.4856344932923093e-05, Val Loss: 0.0018119591986760497\n",
      "Epoch 94, Train Loss: 1.5228155461954884e-05, Val Loss: 0.001808346714824438\n",
      "Epoch 95, Train Loss: 1.3197544831200503e-05, Val Loss: 0.0018051797524094582\n",
      "Epoch 96, Train Loss: 1.3433114872896113e-05, Val Loss: 0.0018110204255208373\n",
      "Epoch 97, Train Loss: 1.1497208106447943e-05, Val Loss: 0.0018200089689344168\n",
      "Epoch 98, Train Loss: 1.146241538663162e-05, Val Loss: 0.0018173118587583303\n",
      "Epoch 99, Train Loss: 9.548819434712641e-06, Val Loss: 0.001816305797547102\n",
      "Epoch 100, Train Loss: 9.267785571864806e-06, Val Loss: 0.00182334054261446\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set evaluation results:\n",
      "R2: 0.9994573257528008, RMSEP: 0.0038521097617428236, MAE: 0.00256062438711524, MAX_ERROR: 0.009753882884979248\n",
      "Validation set evaluation results:\n",
      "R2: 0.8592947373860085, RMSEP: 0.06038775351983296, MAE: 0.05041588097810745, MAX_ERROR: 0.11481696367263794\n",
      "Test set evaluation results:\n",
      "R2: 0.9128151722928556, RMSEP: 0.05170465818895236, MAE: 0.042826605694634576, MAX_ERROR: 0.11463791877031326\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def load_data():\n",
    "    Path2 =  'oil-data\\\\iRaman_processed_spectra.csv'\n",
    "    X = pd.read_csv(Path2, header=None, index_col=None).values\n",
    "    y_path = 'oil-data\\\\Olive oil labels.csv'\n",
    "    y = pd.read_csv(y_path, header=None).values.reshape(-1)\n",
    "    return X, y\n",
    "\n",
    "def split_data(X, y):\n",
    "    X_trans, X_val, y_trans, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=42)\n",
    "\n",
    "    X_train, X_left, y_train, y_left = train_test_split(X_trans, y_trans, test_size=0.85, random_state=12)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "def create_dataloaders(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "    X_val = torch.tensor(X_val, dtype=torch.float32, device=device)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.float32, device=device)\n",
    "    y_val = torch.tensor(y_val, dtype=torch.float32, device=device)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.float32, device=device)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=len(y_train), shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=len(y_val), shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=len(y_test), shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def get_peft_model(base_model, lora_rank, lora_alpha):\n",
    "    class PeftModel(nn.Module):\n",
    "        np.random.seed(42)\n",
    "        torch.manual_seed(42)\n",
    "        def __init__(self, base_model, lora_rank, lora_alpha):\n",
    "            super(PeftModel, self).__init__()\n",
    "            for name, module in base_model.named_children():\n",
    "                if name != 'Linear':\n",
    "                    self.add_module(name, module)\n",
    "                else:\n",
    "                    self.add_module(name, lora.Linear(base_model.Linear.in_features, base_model.Linear.out_features, r=lora_rank, lora_alpha=lora_alpha, merge_weights=True))\n",
    "            \n",
    "        def forward(self, x):\n",
    "            for module in self.children():\n",
    "                x = module(x)\n",
    "            return x.squeeze(dim=1)\n",
    "    \n",
    "    return PeftModel(base_model, lora_rank, lora_alpha)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, learning_rate, weight_decay):\n",
    "    model.to(device)\n",
    "    loss_fn = nn.SmoothL1Loss().to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    epochs = 100\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x = batch_x.unsqueeze(dim=1).to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            outputs = model(batch_x)\n",
    "            loss = loss_fn(outputs, batch_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in val_loader:\n",
    "                batch_x = batch_x.unsqueeze(dim=1).to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "                output = model(batch_x)\n",
    "                loss = loss_fn(output, batch_y)\n",
    "                val_loss += loss.item()\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_losses[-1]}, Val Loss: {val_losses[-1]}')\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n",
    "def plot_learning_curve(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(model, loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in loader:\n",
    "            batch_x = batch_x.unsqueeze(dim=1).to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            output = model(batch_x)\n",
    "            predictions.extend(output.cpu().tolist())\n",
    "            actuals.extend(batch_y.cpu().tolist())\n",
    "    final_r2 = r2_score(actuals, predictions)\n",
    "    RMSEP = root_mean_squared_error(actuals, predictions)\n",
    "    MAE = mean_absolute_error(actuals, predictions)\n",
    "    MAX_ERROR = max_error(actuals, predictions)\n",
    "    return final_r2, RMSEP, MAE, MAX_ERROR\n",
    "\n",
    "def save_model(model, filename):\n",
    "    torch.save(model.state_dict(), filename)\n",
    "\n",
    "\n",
    "def main():\n",
    "    with open('lora_peft_best_hyperparameters_15%.json', 'r') as f:\n",
    "        best_params = json.load(f)\n",
    "    \n",
    "    learning_rate = best_params['Learning rate']\n",
    "    weight_decay = best_params['Regularization coefficient']\n",
    "    lora_rank = int(best_params['Lora rank'])\n",
    "    lora_alpha = lora_rank\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    X, y = load_data()\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y)\n",
    "    train_loader, val_loader, test_loader = create_dataloaders(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "    \n",
    "    base_model = CNN()\n",
    "    peft_model = get_peft_model(base_model, lora_rank, lora_alpha).to(device)\n",
    "\n",
    "    model_state_dict = torch.load('oil-best_model_cnn_x1.pt', map_location=device, weights_only=True)\n",
    "    peft_model.load_state_dict(model_state_dict, strict=False)\n",
    "\n",
    "    # Perform weight decay\n",
    "    original_weight = peft_model.Linear.weight.data\n",
    "    decayed_weight = original_weight * 0.5\n",
    "    peft_model.Linear.weight.data = decayed_weight\n",
    "    #Confirm the layers to be trained\n",
    "    lora.mark_only_lora_as_trainable(peft_model)\n",
    "   \n",
    "    train_losses, val_losses = train_model(peft_model, train_loader, val_loader,learning_rate, weight_decay)\n",
    "    plot_learning_curve(train_losses, val_losses)\n",
    "\n",
    "    print('Training set evaluation results:')\n",
    "    r2, rmse, mae, me = evaluate_model(peft_model, train_loader, device)\n",
    "    print(f'R2: {r2}, RMSEP: {rmse}, MAE: {mae}, MAX_ERROR: {me}')\n",
    "\n",
    "    print('Validation set evaluation results:')\n",
    "    r2, rmse, mae, me = evaluate_model(peft_model, val_loader, device)\n",
    "    print(f'R2: {r2}, RMSEP: {rmse}, MAE: {mae}, MAX_ERROR: {me}')\n",
    "\n",
    "    print('Test set evaluation results:')\n",
    "    r2, rmse, mae, me = evaluate_model(peft_model, test_loader, device)\n",
    "    print(f'R2: {r2}, RMSEP: {rmse}, MAE: {mae}, MAX_ERROR: {me}')\n",
    "    \n",
    "\n",
    "    # Save the weights of the lora module\n",
    "    torch.save(lora.lora_state_dict(peft_model), 'lora_state_dict_15%.pt')\n",
    "    save_dict = {}\n",
    "    # Save the weights of the fine-tuned BN layer\n",
    "    model_state = peft_model.state_dict()\n",
    "    for k,v in model_state.items():\n",
    "        if 'BatchNorm' in k:\n",
    "            save_dict[k] = v\n",
    "    torch.save(save_dict, 'peft_model_BN_15%.pt')\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
